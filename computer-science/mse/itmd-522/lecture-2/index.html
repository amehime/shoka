<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="優萌初華" href="https://shoka.lostyu.me/rss.xml"><link rel="alternate" type="application/atom+xml" title="優萌初華" href="https://shoka.lostyu.me/atom.xml"><link rel="alternate" type="application/json" title="優萌初華" href="https://shoka.lostyu.me/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="机器学习,数据挖掘"><link rel="canonical" href="https://shoka.lostyu.me/computer-science/mse/itmd-522/lecture-2/"><meta name="description" content="Emphasis: understand the techniques  What it is What problems it can solve In which situations we should use them Any limitations or requirements to use them How to evaluate them  # Supervised v.s. Un"><meta property="og:type" content="article"><meta property="og:title" content="Lecture 2. Supervised Learning 监督学习"><meta property="og:url" content="https://shoka.lostyu.me/computer-science/mse/itmd-522/lecture-2/"><meta property="og:site_name" content="優萌初華"><meta property="og:description" content="Emphasis: understand the techniques  What it is What problems it can solve In which situations we should use them Any limitations or requirements to use them How to evaluate them  # Supervised v.s. Un"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://s2.loli.net/2022/01/25/G8hfwm1jLdU3Jvg.png"><meta property="og:image" content="https://s2.loli.net/2022/01/29/YlfogI8UqCQSjW6.jpg"><meta property="og:image" content="https://s2.loli.net/2022/01/29/iRguC52JhADMTIN.jpg"><meta property="og:image" content="https://s2.loli.net/2022/01/29/GTiEh8Wa9orlSf1.jpg"><meta property="og:image" content="https://s2.loli.net/2022/01/29/xPqd9yFmjMCoQcO.png"><meta property="og:image" content="https://s2.loli.net/2022/01/29/zRMrPyJqcBUmsnf.jpg"><meta property="og:image" content="https://s2.loli.net/2022/01/29/ZLiUpyroMHjWAJB.png"><meta property="og:image" content="https://s2.loli.net/2022/01/29/1KIeyGvsbPiCOH8.png"><meta property="og:image" content="https://s2.loli.net/2022/01/29/LbE7A439UV2h1oT.png"><meta property="og:image" content="https://s2.loli.net/2022/01/30/pXtgUQz6euC2dxE.png"><meta property="og:image" content="https://s2.loli.net/2022/01/30/T3LMBURp6vekzr9.png"><meta property="og:image" content="https://s2.loli.net/2022/01/30/VXKDhoecLsPput4.png"><meta property="og:image" content="https://s2.loli.net/2022/01/30/GBAFZyLjnhcPqXs.jpg"><meta property="og:image" content="https://s2.loli.net/2022/01/30/mBGu7tsSjoYVRpH.png"><meta property="article:published_time" content="2022-01-25T04:01:07.000Z"><meta property="article:modified_time" content="2022-01-25T04:01:07.000Z"><meta property="article:author" content="Ruri Shimotsuki"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="数据挖掘"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://s2.loli.net/2022/01/25/G8hfwm1jLdU3Jvg.png"><meta name="twitter:creator" content="@amehime"><title>Lecture 2. Supervised Learning 监督学习 - ITMD 522. Data Mining and Machine Learning - Master of Software Engineering - 计算机科学 | Yume Shoka = 優萌初華 = 有夢書架</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Lecture 2. Supervised Learning 监督学习</h1><div class="meta"><span class="item" title="创建时间：2022-01-25 12:01:07"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-01-25T12:01:07+08:00">2022-01-25</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>6.9k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>6 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/31105e606c74614c7f8f7b1d08e1619a.jpg"></li><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/f534e931ecbd67c0161d82dabb45ca42.jpg"></li><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/132a88e4e5cfe7e3847ed93deae688d2.jpg"></li><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/d98b6decf4bed33201f3217c864cf5a3.jpg"></li><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/d4df076eb51491f02d9c9754567256fb.jpg"></li><li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/92d1abba680eeb2b1941281d6758fd76.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-science/" itemprop="item" rel="index" title="分类于 计算机科学"><span itemprop="name">计算机科学</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-science/mse/" itemprop="item" rel="index" title="分类于 Master of Software Engineering"><span itemprop="name">Master of Software Engineering</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-science/mse/itmd-522/" itemprop="item" rel="index" title="分类于 ITMD 522. Data Mining and Machine Learning"><span itemprop="name">ITMD 522. Data Mining and Machine Learning</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://shoka.lostyu.me/computer-science/mse/itmd-522/lecture-2/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Ruri Shimotsuki"><meta itemprop="description" content="有夢書架, 琉璃的医学 & 编程笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="優萌初華"></span><div class="body md" itemprop="articleBody"><p>Emphasis: understand the techniques</p><ul><li>What it is</li><li>What problems it can solve</li><li>In which situations we should use them</li><li>Any limitations or requirements to use them</li><li>How to evaluate them</li></ul><h1 id="supervised-vs-unsupervised-learning-监督学习和无监督学习"><a class="anchor" href="#supervised-vs-unsupervised-learning-监督学习和无监督学习">#</a> Supervised v.s. Unsupervised Learning 监督学习和无监督学习</h1><h2 id="supervised-learning-监督学习"><a class="anchor" href="#supervised-learning-监督学习">#</a> Supervised Learning 监督学习</h2><ul><li><p>infer a (predictive) function from data associated with pre defined targets/classes/labels<br>从与预定义的目标 / 类 / 标签相关的数据中推断一个 (预测) 函数</p></li><li><p><strong>Example</strong>: group objects by predefined labels<br>根据预定义的<strong>标签</strong>，对对象进行分组</p></li><li><p><strong>Goal</strong>: Learn a model from labelled data (with multiple features) for future predictions<br>从标记的数据 (具有多种特征) 中学习一个模型，用于未来的预测</p></li><li><p><strong>Outcomes</strong>: We know outcomes: the predefined labels<br>我们知道结果：预先定义的标签</p></li><li><p><strong>Evaluation</strong>: error/accuracy, and other more metrics<br>错误 / 准确性，以及其他更多的指标</p></li><li><p><strong>Data Mining Task</strong>: Classification<br>数据挖掘任务：分类</p></li></ul><h2 id="unsupervised-learning-无监督学习"><a class="anchor" href="#unsupervised-learning-无监督学习">#</a> Unsupervised Learning 无监督学习</h2><ul><li><p>discover or describe underlying structure from unlabelled data<br>从未标记的数据中发现或描述底层结构</p></li><li><p><strong>Example</strong>: group objects by multiple features<br>通过多种<strong>特征</strong>，对对象进行分组</p></li><li><p><strong>Goal</strong>: Learn the structure from unlabelled data (with multiple features)<br>从没有标记的数据 (具有多种特性) 中学习结构</p></li><li><p><strong>Outcomes</strong>: We do not know the outcomes<br>我们不知道结果</p></li><li><p><strong>Evaluation</strong>: No clear performance or evaluation methods<br>没有明确的表现或评估方法</p></li><li><p><strong>Data Mining Task</strong>: Clustering<br>数据挖掘任务：归并</p></li></ul><p><img data-src="https://s2.loli.net/2022/01/25/G8hfwm1jLdU3Jvg.png" alt="" title="Example: Classification - left, Clustering - right"></p><table><thead><tr><th colspan="3">Machine Learning Algorithms 机器学习算法</th></tr><tr><th></th><th>Unsupervised 无监督学习</th><th>Supervised 监督学习</th></tr></thead><tbody><tr><td><p>Continuous 数值型</p></td><td><ul><li>Clustering &amp; Dimensionality Reduction 聚类与降维<ul><li>SVD 奇异值分解</li><li>PCA</li><li>K-means</li></ul></li></ul></td><td><ul><li>Regression 回归<ul><li>Linear 线性</li><li>Polynomial 多项式</li></ul></li><li>Decision Trees 决策树</li><li>Random Forests 随机森林</li></ul></td></tr><tr><td><p>Categorical 标称型</p></td><td><ul><li>Association Analysis 关联分析<ul><li>Apriori 先验推测</li><li>FP-Growth</li></ul></li><li>Hidden Markov Model 隐马尔可夫模型</li></ul></td><td><ul><li>Classification 分类法<ul><li>KNN K - 近邻算法 k-Nearest Neighbor</li><li>Trees<ul><li>Logistic Regression 逻辑回归</li></ul></li><li>Naive-Bayes 朴素贝叶斯</li><li>SVM</li></ul></li></ul></td></tr></tbody></table><h1 id="linear-regression"><a class="anchor" href="#linear-regression">#</a> Linear Regression</h1><ul><li>We have knowledge: values in y<br>已知值取自 y</li><li>We have factors or features: x variables<br>有因素或特征：x 个变量</li><li>We need to split data into training and testing<br>将数据分为培训和测试</li><li>We learned the model from training, and evaluate it on the testing set<br>从训练中学习模型，并在测试集上对其进行评估</li><li>We do have truth in testing test and predictions for test set, as well as evaluation metrics: RMSE, MAE<br>在检测测试集和对测试集的预测，以及评估指标上 RMSE，MAE</li><li>Have a general problem in supervised learning: <strong>overfitting</strong><br>监督学习有一个普遍的问题：过度适应</li></ul><h1 id="classification"><a class="anchor" href="#classification">#</a> Classification</h1><dl><dt>Classification</dt><dd>a supervised way to group objects 一个监督的方式来分组对象<ul><li>We must have predefined labels 必须有预定义的标签</li><li>We must have knowledge: we know some instances are labeled by predefined classes/labels/categories<br>必须有知识：我们知道一些实例是由预定义的类 / 标签 / 类别来标记的</li></ul></dd></dl><ul><li><p>For a Purpose of Prediction 为了预测的目的</p><ul><li>To forecast or deduce the label/class based on values of features<br>根据特征值预测或推断标签 / 类别</li><li>Let the machines/computers think as humans<br>让机器 / 计算机像人一样思考</li></ul></li><li><p>There are many real world applications<br>现实世界中有很多应用程序</p><ul><li>Financial Decision Making, e.g., credit card application<br>财务决策 - 信用卡申请</li><li>Image Processing, e.g., face recognition in cameras<br>图像处理 - 摄像头中的人脸识别</li><li>Computer/Network Security, e.g., virus or attack detection<br>计算机 / 网络安全 - 病毒或攻击检测</li><li>Information Retrieval, e.g., relevance of a document to a query<br>信息检索 - 文档与查询的相关性</li><li>Recommender Systems, e.g., rating prediction for Amazon<br>推荐系统 - 亚马逊的评级预测</li></ul></li></ul><blockquote><p>Example - Classification App: Credit Card Application</p><p class="gallery" data-height="120"><img data-src="https://s2.loli.net/2022/01/29/YlfogI8UqCQSjW6.jpg" alt="" title="Identity"><br><img data-src="https://s2.loli.net/2022/01/29/iRguC52JhADMTIN.jpg" alt="" title="Financial situation"><br><img data-src="https://s2.loli.net/2022/01/29/GTiEh8Wa9orlSf1.jpg" alt="" title="3 types of answers; can consider this result as a nominal variable with three values"></p><p>Terminologies in Classification<br>分类术语<br><img data-src="https://s2.loli.net/2022/01/29/xPqd9yFmjMCoQcO.png" alt=""></p><ul><li>Features 特征<ul><li>Each row with features values is named as example or instance 带有特征值的每一行都被命名为示例或实例</li></ul></li><li>Classes 分类</li><li>Knowledge 知识</li><li>Unseen data</li></ul><dl><dt>Classification</dt><dd><ul><li>Learn from the knowledge (examples with unknown labels)<br>从 knowledge 中学习（标签未知的示例）</li><li>build predictive models to predict the unknown examples<br>建立预测模型来预测未知的例子</li></ul></dd></dl></blockquote><h2 id="classification-task-任务"><a class="anchor" href="#classification-task-任务">#</a> Classification Task 任务</h2><p>There are usually three types of classification:<br>通常有三种分类</p><ol><li><p>Binary Classification 二元分类<br>Question: Is this an apple? Yes or No.<br>问题：这是苹果吗？是或否。</p></li><li><p>Multi-class Classification 多类分类<br>Question: Is this an apple, banana or orange?<br>问题：这是苹果、香蕉还是橘子？</p></li><li><p>Multi-label Classification 多标签分类<br>Use appropriate words to describe it: Red, Apple, Fruit , Tech, Mac, iPhone<br>用适当的词来描述它：红色、苹果、水果、科技、Mac、iPhone</p></li></ol><p><img data-src="https://s2.loli.net/2022/01/29/zRMrPyJqcBUmsnf.jpg" alt="" title="Color, Shape, Weight, Origin, Taste, Price, Vitamin c" height="100px"></p><blockquote><p>We use binary classification as examples to introduce classification techniques.<br>我们以二元分类为例介绍分类技术。</p><p>But most of these classification methods can handle multi class classifications too.<br>但大多数分类方法也可以处理多类分类。</p><p>There are different strategies to handle multi class classifications.<br>有不同的策略来处理多类分类。</p></blockquote><h2 id="standard-classification-process-标准分类流程"><a class="anchor" href="#standard-classification-process-标准分类流程">#</a> Standard Classification Process 标准分类流程</h2><ol><li><strong>Training/Learning</strong>: Learn a model using the <span class="blue">training data</span><br>训练 / 学习：使用训练数据学习模型</li><li><strong>Validation/Test</strong>: Test using <span class="blue">test data</span> to assess accuracy<br>验证 / 测试：使用测试数据评估准确性</li><li><strong>Application/Predictions</strong>: Apply the selected model to <span class="orange">unseen data</span><br>应用 / 预测：将所选模型应用于看不见的数据</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Accuracy</mtext><mo>=</mo><mfrac><mtext>Number of correct classifications</mtext><mtext>Total number of test cases</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text { Accuracy }=\frac{\text { Number of correct classifications }}{\text { Total number of test cases }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord"> Accuracy </span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord"> Total number of test cases </span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord"> Number of correct classifications </span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><img data-src="https://s2.loli.net/2022/01/29/ZLiUpyroMHjWAJB.png" alt=""></p><h2 id="evaluation-评估"><a class="anchor" href="#evaluation-评估">#</a> Evaluation 评估</h2><p>How could we know it is good or bad?</p><p>Data Splits for Evaluations 将数据拆分来进行评估</p><ul><li>There are several ways to split your data for evaluations<br>有几种方法可以分割数据进行评估<ul><li>Hold-out evaluation</li><li>N-fold cross validation N 倍交叉验证</li><li>Leave one out evaluation</li><li>Stratified N fold cross validation</li><li>...</li></ul></li></ul><h3 id="hold-out-evaluation"><a class="anchor" href="#hold-out-evaluation">#</a> Hold-out evaluation</h3><blockquote><p>If your data is large enough<br>数据足够大的时候使用</p></blockquote><p><img data-src="https://s2.loli.net/2022/01/29/1KIeyGvsbPiCOH8.png" alt=""></p><p>方法一：将 Knowledge 随机分成两部分，一组为 Training Data，一组为 Test Data，通常训练集要大一些 70-80%。</p><p><img data-src="https://s2.loli.net/2022/01/29/LbE7A439UV2h1oT.png" alt=""></p><p>方法二：将 Knowledge 分成三部分，Training Data，Validation Data，用来 Training, evaluating and tunning model parameters，模型参数的训练、评估和调整，以及 Testing Data，Report results on testing set only 仅在测试集上报告结果。这种情况下可以用 Validation 和 Test 两组数据进行评估，最终报告仅基于 Testing data，结果更可靠。</p><h3 id="n-folds-cross-evaluation-n倍交叉验证"><a class="anchor" href="#n-folds-cross-evaluation-n倍交叉验证">#</a> N-folds Cross Evaluation N 倍交叉验证</h3><blockquote><p>If your data is relatively small</p></blockquote><p><img data-src="https://s2.loli.net/2022/01/30/pXtgUQz6euC2dxE.png" alt=""></p><p>需要定一个 N ，可以选择任何一个大于 2 的整数，一般可以是 5 或者 10。<br>将数据随机平均分成 N 个 fold。<br>第一轮，选择第一个 fold 作为 valitation，其他组作为 training，建立模型，并评估，获得了一个 accuracy。<br>第二轮，选择第二个 fold 作为 valitation，其他组作为 training，建立模型，并评估，获得了另一个 accuracy。<br>以此类推，共做 N 个 Round。</p><p>每轮都选择一个 fold 作为 testing，其余作为 training。<br>最终生成 evaluation matrix，并且报告 average matrix 作为最终 accuracy。</p><h3 id="summary"><a class="anchor" href="#summary">#</a> Summary</h3><ul><li>We always suggest you to use N-fold cross validation, as long as you have enough computational power it doesn’t matter your data is large or small<br>建议使用 N 倍交叉验证，只要有足够的计算能力，数据大小都无关紧要<br>因为 Hold-out 方法总归会有 bias 偏倚，数据量大，bias 会小些</li><li>If your computer is not powerful<ul><li>Data is large =&gt; you can use hold-out</li><li>Data is small =&gt; you can use N-fold cross validation</li><li>No fixed rule to say data is large or small. Usually, a data set with less than 500K rows can be considered as small data<br>没有固定的规则来说明数据的大小。通常，行数小于 500K 的数据集可视为小数据</li></ul></li><li>Common mistakes: some students run both hold-out<br>and N-fold cross validation, and report best results.</li></ul><blockquote><p>选择哪种策略的唯一方法是基于数据量的大小<br>如果数据量小于 500k，直接选择 N-fold cross；数据量大于 500k，但是有大 cpu 或内存，仍然建议 N-fold cross。因为 N-fold cross 更可靠。</p></blockquote><ul><li>How it works</li></ul><p class="gallery" data-height="120"><img data-src="https://s2.loli.net/2022/01/30/T3LMBURp6vekzr9.png" alt="" title="Build a Model"><br><img data-src="https://s2.loli.net/2022/01/30/VXKDhoecLsPput4.png" alt="" title="Predictions"></p><h2 id="general-problem-overfitting-过拟合"><a class="anchor" href="#general-problem-overfitting-过拟合">#</a> General Problem: overfitting 过拟合</h2><dl><dt>Overfitting Problem</dt><dd>The model is over trained by the training set;<br>模型被训练集过度训练；<br>the performance on the testing set (such as accuracy) is significantly worse than the performance on training set<br>测试集上的性能（如准确性）明显低于训练集上的性能</dd></dl><p><img data-src="https://s2.loli.net/2022/01/30/GBAFZyLjnhcPqXs.jpg" alt=""></p><ul><li><p>Example of over trained:<br>过度训练的例子：<br>students can work on questions on the assignment well, but they may not work well on the questions in the exams.<br>学生可以很好地解决作业中的问题，但他们可能无法很好地解决考试中的问题。</p></li><li><p>Is there an overfitting problem?</p><ol><li>Linear Regression Models 线性回归模型<ul><li>M1: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>d</mi><mi>j</mi><mo>−</mo><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Adj-R^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span> = 96%, MAE = 0.36</li><li>M2: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>d</mi><mi>j</mi><mo>−</mo><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Adj-R^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span> = 98%, MAE = 0.6</li></ul><blockquote><p>Adjust R Square tells you how the model performs on the train data set<br>MAE tells you how the model performs on the test data set<br>in the train data set, M2 works better than M1.<br>in the test data set, M2 works worse than M1<br>M2 has overfitting problem.<br>Because theoretically M2 works better than M1 on train data set, so M2 should also works better than M1 on test data set. But unfortunately, the MAE on the test data set is increased.</p></blockquote></li><li>Classification Models 分类模型<ul><li>M1: Accuracy on training = 90%, testing = 85%</li><li>M2: Accuracy on training = 80%, testing = 85%</li><li>M3: Accuracy on training = 85%, testing = 60%</li></ul><blockquote><p>M3 有严重的问题，M1 的情况比较常见，不算严重<br>不管是哪种模型，都要基于 testing data 出报告，而不应该基于 training data</p></blockquote></li></ol></li></ul><h2 id="classification-algorithms"><a class="anchor" href="#classification-algorithms">#</a> Classification Algorithms</h2><p>How to perform classification tasks?<br>如何执行分类任务</p><p>Classification algorithm is the key component in the process<br>分类算法是该过程的关键组成部分</p><p>They are able to learn from training and build models…<br>他们能够从训练中学习并建立模型…</p><p><img data-src="https://s2.loli.net/2022/01/30/mBGu7tsSjoYVRpH.png" alt=""></p><p>There are many (supervised) classification algorithms:</p><ul><li>K-nearest neighbor classifier K 近邻分类器</li><li>Naïve Bayes classifier 朴素贝叶斯分类器</li><li>Decision tress 决策树</li><li>Linear/Logistic regression 线性 / 逻辑回归</li><li>Support Vector Machines 支持向量机</li><li>Ensemble classifiers (e.g., random forest) 集成分类器（如 随机森林）</li><li>Neural Networks 神经网络</li></ul><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 机器学习</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag"><i class="ic i-tag"></i> 数据挖掘</a></div></div><footer><div class="meta"><span id="computer-science/mse/itmd-522/lecture-2/" class="item leancloud_visitors" data-flag-title="Lecture 2. Supervised Learning 监督学习" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Ruri Shimotsuki 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="Ruri Shimotsuki 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="Ruri Shimotsuki 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Ruri Shimotsuki <i class="ic i-at"><em>@</em></i>優萌初華</li><li class="link"><strong>本文链接：</strong> <a href="https://shoka.lostyu.me/computer-science/mse/itmd-522/lecture-2/" title="Lecture 2. Supervised Learning 监督学习">https://shoka.lostyu.me/computer-science/mse/itmd-522/lecture-2/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/computer-science/mse/itmd-522/lecture-1/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;img.timelessq.com&#x2F;images&#x2F;2022&#x2F;07&#x2F;26&#x2F;c370ed4ee6c8ac92941a49e11209fc78.jpg" title="Lecture 1. KDD Process: Data PreProcessing 数据预处理"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> ITMD 522. Data Mining and Machine Learning</span><h3>Lecture 1. KDD Process: Data PreProcessing 数据预处理</h3></a></div><div class="item right"><a href="/computer-science/mse/itmd-522/lecture-3/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;img.timelessq.com&#x2F;images&#x2F;2022&#x2F;07&#x2F;26&#x2F;f885d5531d4b21d05f954f61b036adc0.jpg" title="Lecture 3. Supervised Learning: Classification Algorithms Part.1 监督学习:分类算法1"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> ITMD 522. Data Mining and Machine Learning</span><h3>Lecture 3. Supervised Learning: Classification Algorithms Part.1 监督学习:分类算法1</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#supervised-vs-unsupervised-learning-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">Supervised v.s. Unsupervised Learning 监督学习和无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#supervised-learning-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.1.</span> <span class="toc-text">Supervised Learning 监督学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#unsupervised-learning-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.2.</span> <span class="toc-text">Unsupervised Learning 无监督学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#linear-regression"><span class="toc-number">2.</span> <span class="toc-text">Linear Regression</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#classification"><span class="toc-number">3.</span> <span class="toc-text">Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#classification-task-%E4%BB%BB%E5%8A%A1"><span class="toc-number">3.1.</span> <span class="toc-text">Classification Task 任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#standard-classification-process-%E6%A0%87%E5%87%86%E5%88%86%E7%B1%BB%E6%B5%81%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">Standard Classification Process 标准分类流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#evaluation-%E8%AF%84%E4%BC%B0"><span class="toc-number">3.3.</span> <span class="toc-text">Evaluation 评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hold-out-evaluation"><span class="toc-number">3.3.1.</span> <span class="toc-text">Hold-out evaluation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#n-folds-cross-evaluation-n%E5%80%8D%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">3.3.2.</span> <span class="toc-text">N-folds Cross Evaluation N 倍交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#summary"><span class="toc-number">3.3.3.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#general-problem-overfitting-%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">3.4.</span> <span class="toc-text">General Problem: overfitting 过拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#classification-algorithms"><span class="toc-number">3.5.</span> <span class="toc-text">Classification Algorithms</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/computer-science/mse/itmd-522/lecture-1/" rel="bookmark" title="Lecture 1. KDD Process: Data PreProcessing 数据预处理">Lecture 1. KDD Process: Data PreProcessing 数据预处理</a></li><li class="active"><a href="/computer-science/mse/itmd-522/lecture-2/" rel="bookmark" title="Lecture 2. Supervised Learning 监督学习">Lecture 2. Supervised Learning 监督学习</a></li><li><a href="/computer-science/mse/itmd-522/lecture-3/" rel="bookmark" title="Lecture 3. Supervised Learning: Classification Algorithms Part.1 监督学习:分类算法1">Lecture 3. Supervised Learning: Classification Algorithms Part.1 监督学习:分类算法1</a></li><li><a href="/computer-science/mse/itmd-522/lecture-4/" rel="bookmark" title="Lecture 4. Supervised Learning: Classification Algorithms Part.2 监督学习:分类算法2">Lecture 4. Supervised Learning: Classification Algorithms Part.2 监督学习:分类算法2</a></li><li><a href="/computer-science/mse/itmd-522/lecture-5/" rel="bookmark" title="Lecture 5. Supervised Learning: Classification Algorithms Part.3 监督学习:分类算法3">Lecture 5. Supervised Learning: Classification Algorithms Part.3 监督学习:分类算法3</a></li><li><a href="/computer-science/mse/itmd-522/lecture-6/" rel="bookmark" title="Lecture 6. Unsupervised Learning: Clustering Techniques 无监督学习:聚类技术">Lecture 6. Unsupervised Learning: Clustering Techniques 无监督学习:聚类技术</a></li><li><a href="/computer-science/mse/itmd-522/lecture-7/" rel="bookmark" title="Lecture 7. Association Rules & Web Mining">Lecture 7. Association Rules & Web Mining</a></li><li><a href="/computer-science/mse/itmd-522/lecture-8/" rel="bookmark" title="Lecture 8. Feature Selection and Reduction & Outlier Detection">Lecture 8. Feature Selection and Reduction & Outlier Detection</a></li><li><a href="/computer-science/mse/itmd-522/mid-term/" rel="bookmark" title="Midterm Review">Midterm Review</a></li><li><a href="/computer-science/mse/itmd-522/lecture-9/" rel="bookmark" title="Lecture 9. Data Manipulation with Pandas">Lecture 9. Data Manipulation with Pandas</a></li><li><a href="/computer-science/mse/itmd-522/lecture-10/" rel="bookmark" title="Lecture 10. Classifications by Python">Lecture 10. Classifications by Python</a></li><li><a href="/computer-science/mse/itmd-522/lecture-11/" rel="bookmark" title="Lecture 11. Python for Unsupervised Learning">Lecture 11. Python for Unsupervised Learning</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Ruri Shimotsuki" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Ruri Shimotsuki</p><div class="description" itemprop="description">琉璃的医学 & 编程笔记</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">303</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">68</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">73</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWU=" title="https:&#x2F;&#x2F;github.com&#x2F;amehime"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9hbWVoaW1l" title="https:&#x2F;&#x2F;twitter.com&#x2F;amehime"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9hbWVoaW1l" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;amehime"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTEyODg2ODIz" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;12886823"><i class="ic i-cloud-music"></i></span> <span class="exturl item telegram" data-url="aHR0cHM6Ly90Lm1lL2FtZWhpbWU=" title="https:&#x2F;&#x2F;t.me&#x2F;amehime"><i class="ic i-paper-plane"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9hbWVoaW1l" title="https:&#x2F;&#x2F;about.me&#x2F;amehime"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a><ul class="submenu"><li class="item"><a href="/about/yume" rel="section"><i class="ic i-cloud"></i>自设</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>链环</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/webstack/" rel="section"><i class="ic i-star"></i>网址</a></li></ul></li><li class="item"><span class="exturl" data-url="aHR0cHM6Ly90cmF2ZWxsaW5ncy5saW5r"><i class="ic i-paper-plane"></i>开往</span></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/computer-science/mse/itmd-522/lecture-1/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/computer-science/mse/itmd-522/lecture-3/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/inter-discipline/" title="分类于 交叉学科">交叉学科</a> <i class="ic i-angle-right"></i> <a href="/categories/inter-discipline/artificial-intelligence/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/inter-discipline/artificial-intelligence/machine-learning/" title="分类于 Machine Learning - Stanford">Machine Learning - Stanford</a> <i class="ic i-angle-right"></i> <a href="/categories/inter-discipline/artificial-intelligence/machine-learning/course-1/" title="分类于 Supervised Machine Learning - Regression and Classification">Supervised Machine Learning - Regression and Classification</a></div><span><a href="/inter-discipline/artificial-intelligence/machine-learning/course-1/week-1/" title="Week 01 - Introduction to Machine Learning">Week 01 - Introduction to Machine Learning</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/" title="分类于 Master of Software Engineering">Master of Software Engineering</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/itmm-571/" title="分类于 ITMM 571. Project Management">ITMM 571. Project Management</a></div><span><a href="/computer-science/mse/itmm-571/lecture-12/" title="Lecture 12. Risk Management">Lecture 12. Risk Management</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/certificate/" title="分类于 证书">证书</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/certificate/pmp/" title="分类于 项目管理">项目管理</a></div><span><a href="/computer-science/certificate/pmp/chapter-10/" title="第10章 项目沟通管理">第10章 项目沟通管理</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/" title="分类于 Master of Software Engineering">Master of Software Engineering</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/itmd-514/" title="分类于 ITMD 514. Programming for Data Analytics">ITMD 514. Programming for Data Analytics</a></div><span><a href="/computer-science/mse/itmd-514/week-10/" title="Week 10. Simple Linear Regression 简单线性回归">Week 10. Simple Linear Regression 简单线性回归</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/inter-discipline/" title="分类于 交叉学科">交叉学科</a> <i class="ic i-angle-right"></i> <a href="/categories/inter-discipline/artificial-intelligence/" title="分类于 人工智能">人工智能</a></div><span><a href="/inter-discipline/artificial-intelligence/note-1/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/clinical-medicine/" title="分类于 临床医学">临床医学</a> <i class="ic i-angle-right"></i> <a href="/categories/clinical-medicine/intermediate/" title="分类于 中级资格考试">中级资格考试</a> <i class="ic i-angle-right"></i> <a href="/categories/clinical-medicine/intermediate/course-1/" title="分类于 内科基础知识">内科基础知识</a></div><span><a href="/clinical-medicine/intermediate/course-1/symptom-11/" title="症状11 呕血">症状11 呕血</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/clinical-medicine/" title="分类于 临床医学">临床医学</a> <i class="ic i-angle-right"></i> <a href="/categories/clinical-medicine/cardiovascular/" title="分类于 心血管病学">心血管病学</a> <i class="ic i-angle-right"></i> <a href="/categories/clinical-medicine/cardiovascular/echocardiography/" title="分类于 超声心动图">超声心动图</a> <i class="ic i-angle-right"></i> <a href="/categories/clinical-medicine/cardiovascular/echocardiography/basics/" title="分类于 第一阶段 Basics">第一阶段 Basics</a></div><span><a href="/clinical-medicine/cardiovascular/echocardiography/basics/course-12/" title="12. Use of Contrast in Echocardiography 超声心动图检查中造影剂的使用">12. Use of Contrast in Echocardiography 超声心动图检查中造影剂的使用</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/" title="分类于 Master of Software Engineering">Master of Software Engineering</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/mse/itmm-571/" title="分类于 ITMM 571. Project Management">ITMM 571. Project Management</a></div><span><a href="/computer-science/mse/itmm-571/lecture-3/" title="Lecture 3. Communications Management">Lecture 3. Communications Management</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/java/course-2/" title="分类于 面向对象程序设计 - Java 语言 - 浙江大学 - 翁恺">面向对象程序设计 - Java 语言 - 浙江大学 - 翁恺</a></div><span><a href="/computer-science/java/course-2/week-1/" title="第1周 类与对象">第1周 类与对象</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/useless-stuff/" title="分类于 空谷幽兰">空谷幽兰</a> <i class="ic i-angle-right"></i> <a href="/categories/useless-stuff/tourism/" title="分类于 导游资格">导游资格</a> <i class="ic i-angle-right"></i> <a href="/categories/useless-stuff/tourism/course-3/" title="分类于 科目三 - 全国导基">科目三 - 全国导基</a></div><span><a href="/useless-stuff/tourism/course-3/quiz-3/" title="题库 - 中国历史文化知识">题库 - 中国历史文化知识</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Ruri Shimotsuki @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">3.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">51:02</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"computer-science/mse/itmd-522/lecture-2/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?60ab4a51924a588bb4d810652c9412f1";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></body></html>